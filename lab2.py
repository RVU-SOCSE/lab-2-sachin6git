# -*- coding: utf-8 -*-
"""Lab2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pjI1F1Sj0lXDuXcoRlExJnaHsjX_mLP_

## Bagging and Random Forests

- Problem: Predict whether a student Passes (1) or Fails (0) based on Study Hours and Attendance (%)
"""

import pandas as pd
import warnings

warnings.filterwarnings("ignore")

from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

"""##### Step(1) Generate simple classification dataset"""

# Create dataset
data = {
    "Study_Hours": [1, 2, 3, 4, 5, 6],
    "Attendance": [60, 65, 70, 75, 80, 85],
    "Result": [0, 0, 0, 1, 1, 1]  # 0 = Fail, 1 = Pass
}

df = pd.DataFrame(data)
print(df)

"""##### Step(2) Splitting Features and Target"""

X = df[["Study_Hours", "Attendance"]]
y = df["Result"]

"""##### Step(3) Bagging Using Decision Trees
- Multiple decision trees

- Trained on bootstrap samples

- Final prediction by majority vote
"""

# Base model
base_tree = DecisionTreeClassifier()

# Bagging classifier
bagging_model = BaggingClassifier(
    estimator=base_tree,
    n_estimators=10,
    bootstrap=True,
    random_state=42
)

# Train model
bagging_model.fit(X, y)

"""##### Step(4) Prediction"""

# New student data
new_student = [[3.5, 72]]  # Study hours = 3.5, Attendance = 72%

prediction = bagging_model.predict(new_student)
print("Bagging Prediction:", "Pass" if prediction[0] == 1 else "Fail")

"""#### Step(5) Random Forest Classifier
- Bagging + random feature selection at each split

- Less correlated trees

- Better generalization
"""

rf_model = RandomForestClassifier(
    n_estimators=10,
    random_state=42
)

# Train Random Forest
rf_model.fit(X, y)

"""##### Step(6) Prediction"""

rf_prediction = rf_model.predict(new_student)
print("Random Forest Prediction:", "Pass" if rf_prediction[0] == 1 else "Fail")

